/**
 * @fileoverview SQL File Structure Utilities
 * 
 * Provides utilities for managing the table-based SQL file structure
 * where each table has its own folder with separate files for different
 * database objects (table, indexes, rls, triggers, views).
 * 
 * @author PGRestify Team
 * @since 3.0.0
 */

import { fs } from './fs.js';
import { logger } from './logger.js';
import { getHashService } from './hash-service.js';
import path from 'path';
import chalk from 'chalk';

/**
 * SQL file types in order of application
 */
export const SQL_FILE_TYPES = {
  TABLE: 'table.sql',
  INDEXES: 'indexes.sql',
  RLS: 'rls.sql',
  TRIGGERS: 'triggers.sql',
  VIEWS: 'views.sql'
} as const;

/**
 * Order of SQL file execution (conservative approach)
 */
export const SQL_EXECUTION_ORDER = [
  SQL_FILE_TYPES.TABLE,    // Pass 1: Create all tables first
  SQL_FILE_TYPES.INDEXES,  // Pass 2a: Add indexes
  SQL_FILE_TYPES.RLS,      // Pass 2b: Add RLS policies
  SQL_FILE_TYPES.TRIGGERS, // Pass 2c: Add triggers
  SQL_FILE_TYPES.VIEWS     // Pass 2d: Create views last (may depend on everything)
];

/**
 * Get the SQL schemas directory path
 */
export function getSchemasPath(projectPath: string): string {
  return path.join(projectPath, 'sql', 'schemas');
}

/**
 * Get the path for a specific table folder
 */
export function getTableFolderPath(projectPath: string, tableName: string): string {
  return path.join(getSchemasPath(projectPath), tableName);
}

/**
 * Get the path for a specific SQL file within a table folder
 */
export function getTableSQLFilePath(
  projectPath: string, 
  tableName: string, 
  fileType: typeof SQL_FILE_TYPES[keyof typeof SQL_FILE_TYPES]
): string {
  return path.join(getTableFolderPath(projectPath, tableName), fileType);
}

/**
 * Create table folder structure for a given table
 */
export async function createTableFolderStructure(
  projectPath: string, 
  tableName: string
): Promise<void> {
  const tableFolder = getTableFolderPath(projectPath, tableName);
  
  // Create the table folder
  await fs.ensureDir(tableFolder);
  
  logger.debug(`Created table folder structure for ${tableName}`);
}

/**
 * Write SQL content to a specific table file
 */
export async function writeTableSQL(
  projectPath: string,
  tableName: string,
  fileType: typeof SQL_FILE_TYPES[keyof typeof SQL_FILE_TYPES],
  content: string,
  append: boolean = false
): Promise<void> {
  // Ensure table folder exists
  await createTableFolderStructure(projectPath, tableName);
  
  const filePath = getTableSQLFilePath(projectPath, tableName, fileType);
  const hashService = getHashService(projectPath);
  
  let finalContent: string;
  
  if (append && await fs.exists(filePath)) {
    // Append with timestamp comment
    const existingContent = await fs.readFile(filePath);
    const timestampedContent = appendWithTimestamp(content);
    finalContent = existingContent + '\n\n' + timestampedContent;
    await fs.writeFile(filePath, finalContent);
    logger.debug(`Appended to ${tableName}/${fileType}`);
  } else {
    // Write new file with header
    const header = generateFileHeader(tableName, fileType);
    finalContent = header + '\n\n' + content;
    await fs.writeFile(filePath, finalContent);
    logger.debug(`Created ${tableName}/${fileType}`);
  }
  
  // Track the file write in the hash service
  await hashService.trackFileWrite(filePath, finalContent);
}

/**
 * Append content with timestamp comment
 */
export function appendWithTimestamp(
  content: string,
  command?: string
): string {
  const timestamp = new Date().toISOString();
  let comment = `-- Added by pgrestify on ${timestamp}`;
  
  if (command) {
    comment += `\n-- Command: ${command}`;
  }
  
  return comment + '\n' + content;
}

/**
 * Generate file header for SQL files
 */
export function generateFileHeader(
  tableName: string,
  fileType: string
): string {
  const timestamp = new Date().toISOString();
  const objectType = fileType.replace('.sql', '').toUpperCase();
  
  return `-- ${objectType} for table: ${tableName}
-- Generated by PGRestify
-- Created: ${timestamp}
-- 
-- This file contains ${objectType.toLowerCase()} definitions for the ${tableName} table.
-- Modifications will be appended with timestamps.`;
}

/**
 * Get all table folders in the schemas directory
 */
export async function getAllTableFolders(projectPath: string): Promise<string[]> {
  const schemasPath = getSchemasPath(projectPath);
  
  if (!await fs.exists(schemasPath)) {
    return [];
  }
  
  const entries = await fs.readDir(schemasPath);
  const folders: string[] = [];
  
  for (const entry of entries) {
    const fullPath = path.join(schemasPath, entry);
    const stats = await fs.stat(fullPath);
    if (stats.isDirectory()) {
      folders.push(entry);
    }
  }
  
  return folders
    .sort(); // Alphabetical order for consistency
}

/**
 * Get all SQL files for migration in conservative execution order
 */
export async function getSQLFilesForMigration(projectPath: string): Promise<string[]> {
  const tables = await getAllTableFolders(projectPath);
  const files: string[] = [];
  
  // Sort tables to handle common dependency patterns
  const sortedTables = await sortTablesForMigration(projectPath, tables);
  
  // Apply conservative order: all tables first, then indexes, then RLS, etc.
  for (const fileType of SQL_EXECUTION_ORDER) {
    for (const table of sortedTables) {
      const filePath = getTableSQLFilePath(projectPath, table, fileType);
      if (await fs.exists(filePath)) {
        files.push(filePath);
      }
    }
  }
  
  return files;
}

/**
 * Sort tables based on likely dependencies
 */
async function sortTablesForMigration(projectPath: string, tables: string[]): Promise<string[]> {
  // Priority order for common table patterns
  const priorityPatterns = [
    '_setup',      // Setup/initialization tables first
    'users',       // User tables typically have no dependencies
    'profiles',    // Profiles depend on users
    'authors',     // Authors might depend on users
    'customers',   // Customers might depend on users
    'categories',  // Categories are usually independent
    'tags',        // Tags are usually independent
    'products',    // Products might depend on categories
    'posts',       // Posts depend on authors/categories
    'comments',    // Comments depend on posts/users
    'orders',      // Orders depend on customers/products
    'order_items', // Order items depend on orders
    'post_tags'    // Junction tables last
  ];
  
  // Create a map of table dependencies based on foreign keys
  const dependencies = new Map<string, string[]>();
  
  for (const table of tables) {
    const tableFile = getTableSQLFilePath(projectPath, table, SQL_FILE_TYPES.TABLE);
    if (await fs.exists(tableFile)) {
      const content = await fs.readFile(tableFile);
      const referencedTables = findReferencedTables(content);
      dependencies.set(table, referencedTables.filter(ref => tables.includes(ref)));
    }
  }
  
  // Topological sort to handle dependencies
  const sorted: string[] = [];
  const visiting = new Set<string>();
  const visited = new Set<string>();
  
  function visit(table: string) {
    if (visited.has(table)) return;
    if (visiting.has(table)) {
      // Circular dependency detected, just add it
      sorted.push(table);
      visited.add(table);
      return;
    }
    
    visiting.add(table);
    const deps = dependencies.get(table) || [];
    for (const dep of deps) {
      if (tables.includes(dep)) {
        visit(dep);
      }
    }
    visiting.delete(table);
    
    if (!visited.has(table)) {
      sorted.push(table);
      visited.add(table);
    }
  }
  
  // First, add tables following priority patterns
  for (const pattern of priorityPatterns) {
    const matchingTables = tables.filter(t => t === pattern || t.includes(pattern));
    for (const table of matchingTables) {
      visit(table);
    }
  }
  
  // Then add any remaining tables
  for (const table of tables) {
    visit(table);
  }
  
  return sorted;
}

/**
 * Parse table name from SQL content
 */
export function parseTableNameFromSQL(sqlContent: string): string | null {
  // Try to extract table name from CREATE TABLE statement
  const createTableMatch = sqlContent.match(/CREATE TABLE\s+(?:IF NOT EXISTS\s+)?(?:(\w+)\.)?(\w+)/i);
  if (createTableMatch) {
    return createTableMatch[2];
  }
  
  // Try to extract from ALTER TABLE
  const alterTableMatch = sqlContent.match(/ALTER TABLE\s+(?:(\w+)\.)?(\w+)/i);
  if (alterTableMatch) {
    return alterTableMatch[2];
  }
  
  // Try to extract from CREATE POLICY
  const policyMatch = sqlContent.match(/CREATE POLICY\s+\S+\s+ON\s+(?:(\w+)\.)?(\w+)/i);
  if (policyMatch) {
    return policyMatch[2];
  }
  
  // Try to extract from CREATE INDEX
  const indexMatch = sqlContent.match(/CREATE\s+(?:UNIQUE\s+)?INDEX\s+\S+\s+ON\s+(?:(\w+)\.)?(\w+)/i);
  if (indexMatch) {
    return indexMatch[2];
  }
  
  // Try to extract from CREATE TRIGGER
  const triggerMatch = sqlContent.match(/CREATE\s+(?:OR REPLACE\s+)?TRIGGER\s+\S+\s+(?:BEFORE|AFTER)\s+\S+\s+ON\s+(?:(\w+)\.)?(\w+)/i);
  if (triggerMatch) {
    return triggerMatch[2];
  }
  
  return null;
}

/**
 * Determine which tables are referenced in SQL content
 */
export function findReferencedTables(sqlContent: string): string[] {
  const tables = new Set<string>();
  
  // Find tables in FROM clauses
  const fromMatches = sqlContent.matchAll(/FROM\s+(?:(\w+)\.)?(\w+)/gi);
  for (const match of fromMatches) {
    tables.add(match[2]);
  }
  
  // Find tables in JOIN clauses
  const joinMatches = sqlContent.matchAll(/JOIN\s+(?:(\w+)\.)?(\w+)/gi);
  for (const match of joinMatches) {
    tables.add(match[2]);
  }
  
  // Find tables in REFERENCES clauses (foreign keys)
  const refMatches = sqlContent.matchAll(/REFERENCES\s+(?:(\w+)\.)?(\w+)/gi);
  for (const match of refMatches) {
    tables.add(match[2]);
  }
  
  return Array.from(tables);
}

/**
 * Migrate from old structure to new structure
 */
export async function migrateToNewStructure(projectPath: string): Promise<void> {
  logger.info(chalk.cyan('🔄 Migrating SQL files to new table-based structure...'));
  
  const oldSchemaPath = path.join(projectPath, 'sql', 'schemas');
  const oldFiles = [
    '01_main.sql',
    '02_rls.sql', 
    '03_views.sql',
    '04_triggers.sql',
    '05_indexes.sql'
  ];
  
  // Create backup
  const backupPath = path.join(projectPath, 'sql', 'schemas_backup_' + Date.now());
  if (await fs.exists(oldSchemaPath)) {
    await fs.ensureDir(backupPath);
    // Copy files manually since fs.copy doesn't exist
    for (const file of oldFiles) {
      const oldFilePath = path.join(oldSchemaPath, file);
      if (await fs.exists(oldFilePath)) {
        const content = await fs.readFile(oldFilePath);
        await fs.writeFile(path.join(backupPath, file), content);
      }
    }
    logger.info(`📦 Backup created at: ${backupPath}`);
  }
  
  // Process each old file
  for (const oldFile of oldFiles) {
    const oldFilePath = path.join(oldSchemaPath, oldFile);
    if (!await fs.exists(oldFilePath)) {
      continue;
    }
    
    const content = await fs.readFile(oldFilePath);
    const fileType = determineFileType(oldFile);
    
    // Parse and split content by table
    const sections = splitSQLByTable(content);
    
    for (const { tableName, sql } of sections) {
      if (tableName && fileType) {
        await writeTableSQL(projectPath, tableName, fileType, sql);
        logger.success(`✅ Migrated ${tableName} ${fileType}`);
      }
    }
    
    // Remove old file after successful migration
    await fs.remove(oldFilePath);
  }
  
  logger.success('🎉 Migration to new structure complete!');
}

/**
 * Determine file type from old numbered filename
 */
function determineFileType(filename: string): typeof SQL_FILE_TYPES[keyof typeof SQL_FILE_TYPES] | null {
  if (filename.includes('main')) return SQL_FILE_TYPES.TABLE;
  if (filename.includes('rls')) return SQL_FILE_TYPES.RLS;
  if (filename.includes('views')) return SQL_FILE_TYPES.VIEWS;
  if (filename.includes('triggers')) return SQL_FILE_TYPES.TRIGGERS;
  if (filename.includes('indexes')) return SQL_FILE_TYPES.INDEXES;
  return null;
}

/**
 * Split SQL content by table
 */
function splitSQLByTable(content: string): Array<{ tableName: string | null, sql: string }> {
  const sections: Array<{ tableName: string | null, sql: string }> = [];
  const lines = content.split('\n');
  
  let currentSection: string[] = [];
  let currentTable: string | null = null;
  
  for (const line of lines) {
    // Check if this line starts a new table-related statement
    const tableName = parseTableNameFromSQL(line);
    
    if (tableName && tableName !== currentTable) {
      // Save previous section if exists
      if (currentSection.length > 0 && currentTable) {
        sections.push({
          tableName: currentTable,
          sql: currentSection.join('\n').trim()
        });
      }
      
      // Start new section
      currentTable = tableName;
      currentSection = [line];
    } else {
      currentSection.push(line);
    }
  }
  
  // Save last section
  if (currentSection.length > 0 && currentTable) {
    sections.push({
      tableName: currentTable,
      sql: currentSection.join('\n').trim()
    });
  }
  
  return sections;
}

/**
 * Validate the new structure is correctly set up
 */
export async function validateStructure(projectPath: string): Promise<boolean> {
  const tables = await getAllTableFolders(projectPath);
  
  if (tables.length === 0) {
    logger.warn('No table folders found in new structure');
    return false;
  }
  
  let isValid = true;
  
  for (const table of tables) {
    const tableFolder = getTableFolderPath(projectPath, table);
    const hasTableFile = await fs.exists(path.join(tableFolder, SQL_FILE_TYPES.TABLE));
    
    if (!hasTableFile) {
      logger.warn(`⚠️  Table folder ${table} missing table.sql file`);
      isValid = false;
    }
  }
  
  return isValid;
}

/**
 * Get command string from process arguments
 */
export function getCommandString(): string {
  return process.argv.slice(2).join(' ');
}